## 0. 创建虚拟环境

使用[[虚拟环境|conda创建虚拟环境]]并激活


## 1. 安装

```shell
conda install -c conda-forge scrapy
```

>**注意：**
>1. conda环境下最好不要使用pip来安装
>2. 最好保证python版本>3.7，否则可能会出现报错`ModuleNotFoundError: No module named 'typing_extensions'`

升级python版本命令：
```shell
conda update python
```

## 2. 初始化项目

### 2.1 创建项目

```shell
scrapy startproject myproject
```

- myproject：项目名称

### 2.2 创建一个Spider

进入项目目录
```shell
cd myproject
```

创建spider
```shell
scrapy genspider example_spider example.com
```
- example.com：替换为爬取的网站

### 2.3 编写逻辑

在创建的spider文件中，编写爬取逻辑

## 3. 运行项目

在项目目录下运行以下命令启动Spider：
```shell
scrapy crawl example_spider
```

替换 `example_spider` 为你实际创建的Spider的名称。