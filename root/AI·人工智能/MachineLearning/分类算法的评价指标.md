### 意义

分类准确度存在的问题：对于极度偏斜(Skewed Data)的数据，只使用分类准确度远远不够。
>例如：
>一个癌症预测系统，根据输入的体检信息，可以判断是否有癌症，预测准确度可达到99.99%,
>但如果癌症发生的概率有0.01%，这意味着如果预测所有人都是健康，则准确率都可达到99.99%

### 精准率与召回率

```python
from sklearn.metrics import confusion_matrix,precision_score,recall_score,f1_score

confusion_matrix(y_test,y_log_pre)      # 混淆矩阵
```
`y_test`：测试集
`y_log_pre`：使用逻辑回归对`X_test`的预测结果
`confusion_matrix`：混淆矩阵，如下图。
![[精准率与召回率.png]]
- 精准率（precision）
$$
precision=\frac{TP}{TP+FP}
$$
*预测阳性的正确概率*
对于股票预测更注重精准率（我只希望我买的股票大部分是涨的就行了，precision高，猜的越准越好）
```python
precision_score(y_test,y_log_pre)
```

- 召回率（recall）
$$
precision=\frac{TP}{TP+FN}
$$
*召回率=真阳性 / (真阳性+假阴性)*
对于新冠病毒的诊断更注重召回率（我们希望尽可能少漏报患病病例）
```python
recall_score(y_test,y_log_pre)
```

#### F1 Score
F1 Score是为了兼顾精准率与召回率，它描述的是精准率和召回率的调和平均值；
$$
F1=\frac{2*precision*recall}{precision+recall}
$$
>注意：
>F1 Score的取值范围是0到1，**最好的F1 Score是1**，最差的F1 Score是0
>如果精准率与召回率二者极度不平衡，则F1 Score很低；
>只有两者都很高，则F1 Score的分数才会很高。
```python
f1_score(y_test,y_log_pre)
```


#### Precision-Recall曲线(PR曲线)

横纵坐标分别为不同**阈值**下的召回率Recall和精确率Precision，
蓝色图像便是绘制得到的Precision-Recall曲线。
![[二分类Precision-Recall曲线图.jpg]]

**阈值由小变大，那么便会使得FP变小，精确率便也会由小变大；**
**阈值由小变大，那么便会使得TP变小，召回率便会由大变小。**

代码实现：
根据分类概率获取评分列表与阈值列表
```python
# pred_proba=log_reg.predict_proba(X_test)

from sklearn.metrics import precision_recall_curve
# pred_proba[:,1]:第[1]列的所有数据（阳性的数据）
# 精确率，召回率，阈值
precisions,recalls,thresholds=precision_recall_curve(y_test,pred_proba[:,1])
# precisions最后一个值为无效值，使用时注意应为 precisions[:-1]
# recalls最后一个值为无效值，使用时注意应为 recalls[:-1]
```

分别绘制两种评分的曲线
```python
import matplotlib.pyplot as plt  

plt.plot(thresholds,precisions[:-1],label='precision')    # 精准率曲线
plt.plot(thresholds,recalls[:-1],label='recall')       # 召回率曲线
plt.xlabel('threshold')
plt.ylabel('precision/recall')
plt.legend()
plt.show()
```
output:
![[precision&recall_threshold_curve.png]]

绘制PR曲线
```python
# PR曲线
plt.plot(precisions,recalls)
plt.xlabel('precision')
plt.ylabel('recall')
plt.show()
```
output:
![[precision_recall_curve.png]]

#### ROC曲线
ROC曲线的全名：Receiver Operation Characteristic Curve：接收者操作特征曲线
描述FPR和TPR之间的关系
横轴：FPR 纵轴：TPR

##### FPR
- FPR:（False Positive Rate）所有反类中，被预测成正类的比率
$$
FPR=\frac{FP}{TN+FP}
$$

##### TPR
- TPR:（True Positive Rate）所有正类中，被预测成正类的比率，即召回率， 即TPR=Recall
$$
TPR=recall=\frac{TP}{TP+FN}
$$
代码实现：
```python
from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt  

fprs,tprs,thresholds=roc_curve(y_test,pred_proba[:,1])
plt.plot(fprs,tprs)     # 绘制ROC曲线
plt.xlabel('FPR')
plt.ylabel('TPR')
plt.show()
```
output:
![[ROC_curve.png]]


#### ROC AUC

ROC AUC——ROC Area Under Curve:被定义为ROC曲线下与坐标轴围成的面积，
显然这个面积的数值不会大于1
AUC作为数值可以直观的评价分类器的好坏，值越大越好

代码实现：
```python
from sklearn.metrics import roc_auc_score

roc_auc_score(y_test,pred_proba[:,1])
```